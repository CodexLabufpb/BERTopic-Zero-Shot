{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# üîç AN√ÅLISE DE T√ìPICOS COM BERTopic - INSTRU√á√ïES\n",
        "\n",
        "Este notebook realiza an√°lise autom√°tica de t√≥picos em textos usando intelig√™ncia artificial.\n",
        "Siga os passos abaixo para executar a an√°lise:\n",
        "\n",
        "1. INSTALAR E IMPORTAR (Execute esta c√©lula primeiro)\n",
        "2. CONFIGURA√á√ïES (Enviar o seu arquivo CSV)\n",
        "3. MODELAGEM DE T√ìPICOS (An√°lise principal)\n",
        "4. VISUALIZA√á√ïES (Gr√°ficos e resultados)\n",
        "5. EXPORTA√á√ÉO (Salvar resultados)\n",
        "\n",
        "Dica: Execute as c√©lulas de cima pra baixo, na ordem, usando o bot√£o ‚ñ∂ ao lado de cada uma."
      ],
      "metadata": {
        "id": "Vovd_DMBJhxh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1Ô∏è‚É£ INSTALAR E IMPORTAR DEPEND√äNCIAS\n",
        "\n",
        "A c√©lula abaixo instala e importa todas as bibliotecas necess√°rias.\n",
        "\n",
        "‚úèÔ∏è O que voc√™ precisa fazer:\n",
        "- Apenas execute a c√©lula (n√£o precisa editar nada)\n",
        "- Espere at√© ver a mensagem \"Bibliotecas instaladas com sucesso!\"\n",
        "\n",
        "‚è≥ Tempo estimado: 1-2 minutos\n"
      ],
      "metadata": {
        "id": "Vjdjj1PyJ5t5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Instala√ß√µes e Downloads\n",
        "!pip install spacy bertopic wordcloud pandas\n",
        "!python -m spacy download pt_core_news_sm\n",
        "!python -m spacy download pt_core_news_md\n",
        "!python -m spacy download pt_core_news_lg\n",
        "\n",
        "# 1.1 Importa√ß√µes\n",
        "import pandas as pd\n",
        "import spacy\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from bertopic import BERTopic\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from wordcloud import WordCloud, STOPWORDS\n",
        "import matplotlib.pyplot as plt\n",
        "from plotly.colors import qualitative\n",
        "\n",
        "print(\"‚úÖ Bibliotecas instaladas e importadas com sucesso!\")"
      ],
      "metadata": {
        "id": "6Zk9Z2EiJpbJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**üìõ REINICIAR O KERNEL SE:**  \n",
        "‚úîÔ∏è C√©lulas travando sem erro aparente  \n",
        "‚úîÔ∏è Mensagens de \"biblioteca n√£o encontrada\"  \n",
        "‚úîÔ∏è Sa√≠das inconsistentes entre execu√ß√µes  \n",
        "\n",
        "**üîß COMO REINICIAR:**  \n",
        "1. Menu: `Ambiente de execu√ß√£o` ‚Üí `Reiniciar ambiente...`  \n",
        "2. Ou use o atalho: `Ctrl + M .` (ponto)  \n",
        "3. Execute todas as c√©lulas novamente"
      ],
      "metadata": {
        "id": "OHfShyJaLcyh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2Ô∏è‚É£ CONFIGURA√á√ïES\n",
        "\n",
        "‚úèÔ∏è AJUSTE NA C√âLULA ABAIXO OS PAR√ÇMETROS PRINCIPAIS:\n",
        "\n",
        "1. Caminho do seu arquivo .CSV\n",
        "(clique no √≠cone de pasta üìÅ na coluna √† esquerda, depois em üì§ upload,\n",
        "\n",
        "   *   Clique no √≠cone de pasta üìÅ na coluna √† esquerda;\n",
        "   *   Clique em üì§ upload;\n",
        "   *   Selecione o .CSV do seu computador, aperte Open e OK;\n",
        "   *   Clique com o bot√£o direito no nome do arquivo e aperte em \"Copiar Caminho\";\n",
        "   *   Cole esse caminho entre as aspas na c√©lula abaixo.\n",
        "2. Modelo de linguagem: pt_core_news_sm, pt_core_news_md e pt_core_news_lg, use md como padr√£o, sm para testes r√°pidos, lg apenas se precisar de alta precis√£o.\n",
        "3. Palavras que deseja ignorar na an√°lise (stopwords), √© util para melhorar a qualidade dos t√≥picos identificados, remover ru√≠do, otimizar o tempo de processamento.\n",
        "4. Porcentagem de palavras muito frequentes que ser√£o ignoradas.\n",
        "4. Nome da coluna que cont√©m os textos a analisar (evite nomear as colunas com duas palavras separadas por espa√ßo).\n",
        "5. Par√¢metros avan√ßados do modelo de t√≥picos, consulte a documenta√ß√£o em https://maartengr.github.io/BERTopic/api/bertopic.html (Ex.: min_topic_size: quanto menor o valor, mais t√≥picos s√£o criados.)\n",
        "\n",
        "üîß Dicas:\n",
        "- Altere apenas o que est√° entre aspas\n",
        "- Para adicionar v√°rias stopwords, separe por v√≠rgulas, exemplo: [\"palavra1\", \"palavra2\", \"palavra3\"]\n"
      ],
      "metadata": {
        "id": "liFSzrZOLufh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. #### CONFIGUR√ÅVEIS ####\n",
        "\n",
        "# 2.1 Defina o caminho para o seu CSV no Drive\n",
        "CSV_PATH = '/content/nome-do-seu-arquivo.csv'  # ‚Üê ajuste para o seu caminho\n",
        "\n",
        "# 2.2 Modelo spaCy para tokeniza√ß√£o e POS-tagging. # Ex.: \"pt_core_news_sm\", \"pt_core_news_md\", \"pt_core_news_lg\", \"en_core_web_sm\", etc.\n",
        "SPACY_MODEL = \"pt_core_news_md\"\n",
        "\n",
        "# 2.3 Lista de palavras adicionais que voc√™ quer **for√ßar** a excluir # Exemplo: [\"exemplo\", \"teste\", \"palavradescartar\"]\n",
        "CUSTOM_STOP_WORDS = [\"exemplo\", \"palavradescartar\", \"teste\", \"outrapalavra\"]\n",
        "\n",
        "# 2.4 Descarta tokens que ocorrem em mais de 70% dos documentos\n",
        "MAX_DOC_FREQ = 0.70\n",
        "\n",
        "# 2.5 Nome da coluna do DataFrame que cont√©m o texto a ser analisado. # Exemplo: \"resenha\", \"descricao\", \"comentario\"\n",
        "TEXT_COLUMN = \"nome_da_coluna\"\n",
        "\n",
        "# 2.6 Par√¢metros do BERTopic:\n",
        "#     language: para stop-words e pr√©-processamento (pode ser None para auto-detec√ß√£o)\n",
        "#     n_gram_range: (min, max) n-gramas a considerar\n",
        "#     min_topic_size: n√∫mero m√≠nimo de documentos por t√≥pico\n",
        "BERTOPIC_PARAMS = {\n",
        "    \"language\": \"portuguese\",        # ‚Üê personalize: \"english\", \"spanish\"‚Ä¶\n",
        "    \"n_gram_range\": (1, 2),          # ‚Üê personalize: (1,1) para s√≥ uni-gramas, (2,3) para bi-+tri\n",
        "    \"min_topic_size\": 5              # ‚Üê personalize: 5, 10, 20‚Ä¶\n",
        "}\n",
        "print(\"‚úÖ Configura√ß√µes salvas! Pode prosseguir para a pr√≥xima c√©lula.\")"
      ],
      "metadata": {
        "id": "t0mA6SzWLsBg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2.n Carregue o DataFrame\n",
        "df = pd.read_csv(CSV_PATH, sep=',', encoding='utf-8')\n",
        "\n",
        "# 2.n Selecione a coluna de texto que ser√° trabalhada\n",
        "#    Certifique-se de definir TEXT_COLUMN antes (ex.: \"seu_texto\")\n",
        "texts = df[TEXT_COLUMN].dropna().astype(str).tolist()\n",
        "\n",
        "# 2.n Pronto: agora 'texts' √© uma lista de strings que voc√™ pode passar ao seu pipeline\n",
        "print(f\"Carregados {len(texts)} itens da coluna '{TEXT_COLUMN}'.\")"
      ],
      "metadata": {
        "id": "MFY4-pjTT0xA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2.n Inicializar spaCy\n",
        "nlp = spacy.load(SPACY_MODEL)\n",
        "\n",
        "# 2.n Pr√©-processamento\n",
        "def preprocess(text):\n",
        "    doc = nlp(text)\n",
        "    tokens = []\n",
        "    for token in doc:\n",
        "        lemma = token.lemma_.lower()\n",
        "        if token.is_alpha and not token.is_stop and lemma not in CUSTOM_STOP_WORDS:\n",
        "            tokens.append(lemma)\n",
        "    return \" \".join(tokens)\n",
        "\n",
        "docs = df[TEXT_COLUMN].dropna().astype(str).map(preprocess).tolist()\n",
        "\n",
        "# 4.3 Cria um CountVectorizer que j√° exclui as suas stopwords\n",
        "vectorizer_model = CountVectorizer(\n",
        "    ngram_range=BERTOPIC_PARAMS[\"n_gram_range\"], # Use the value from the dictionary\n",
        "    stop_words=CUSTOM_STOP_WORDS,\n",
        "    max_df=MAX_DOC_FREQ      # ‚Üê filtra termos super-frequentes\n",
        ")"
      ],
      "metadata": {
        "id": "DjfN9CafUDfo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üåü NUVEM DE PALAVRAS - VERIFICA√á√ÉO DE STOPWORDS\n",
        "\n",
        "üîç OBJETIVO DESTA C√âLULA:\n",
        "Visualizar as palavras mais frequentes para ajudar a identificar termos irrelevantes que devem ser adicionados como stopwords.\n",
        "\n",
        "üëâ COMO USAR:\n",
        "1. Execute a c√©lula para gerar a nuvem\n",
        "2. Observe as palavras destacadas\n",
        "3. Se aparecerem termos irrelevantes:\n",
        "   - Volte √† c√©lula de CONFIGUR√ÅVEIS\n",
        "   - Adicione-os em CUSTOM_STOP_WORDS\n",
        "   - Execute novamente as c√©lulas subsequentes\n",
        "\n",
        "üìå EXEMPLOS COMUNS DE STOPWORDS A ADICIONAR:\n",
        "- Nomes de institui√ß√µes\n",
        "- Termos muito gen√©ricos\n",
        "- Palavras repetitivas do seu contexto espec√≠fico"
      ],
      "metadata": {
        "id": "SpBOtt1oUlxv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 5 N√∫vem de palavras para visualizar o dataset.\n",
        "\n",
        "# 5.1 Combine todos os textos num √∫nico string\n",
        "text = \" \".join(docs)\n",
        "\n",
        "# 5.2. Monte o conjunto de stopwords (padr√£o + customizadas)\n",
        "stopwords = STOPWORDS.union(set(CUSTOM_STOP_WORDS))\n",
        "\n",
        "# 5.3. Gere a nuvem de palavras\n",
        "wc = WordCloud(\n",
        "    stopwords=stopwords,\n",
        "    width=800,\n",
        "    height=400,\n",
        "    background_color=\"white\"   # opcional: defina a cor de fundo\n",
        ").generate(text)\n",
        "\n",
        "# 5.4. Exiba o gr√°fico\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.imshow(wc, interpolation=\"bilinear\")\n",
        "plt.axis(\"off\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "y21VI_JxUjVo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3Ô∏è‚É£ MODELAGEM DE T√ìPICOS\n",
        "\n",
        "ETAPA PRINCIPAL: Aqui o modelo ir√°:\n",
        "1. Analisar todos os textos\n",
        "2. Identificar padr√µes\n",
        "3. Agrupar em t√≥picos tem√°ticos\n",
        "\n",
        "‚è≥ Tempo estimado: Varia conforme quantidade de textos\n",
        "   (2-10 minutos para conjuntos m√©dios)\n",
        "\n",
        "üîç O que ser√° mostrado:\n",
        "- Tabela com t√≥picos encontrados e suas frequ√™ncias\n",
        "- Palavras-chave de cada t√≥pico\n",
        "- Amostra dos dados classificados"
      ],
      "metadata": {
        "id": "k6Z75vzB9Cnf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title ‚öôÔ∏è Inicializa√ß√£o do BERTopic\n",
        "\n",
        "# 3.1 Inicialize o BERTopic com TODAS as configura√ß√µes da c√©lula de par√¢metros\n",
        "topic_model = BERTopic(\n",
        "    language=BERTOPIC_PARAMS[\"language\"],       # Usa o idioma definido nos par√¢metros\n",
        "    vectorizer_model=vectorizer_model,          # Vectorizer que j√° criamos com MAX_DOC_FREQ\n",
        "    min_topic_size=BERTOPIC_PARAMS[\"min_topic_size\"],  # Tamanho m√≠nimo do t√≥pico\n",
        "    n_gram_range=BERTOPIC_PARAMS[\"n_gram_range\"]       # Faixa de n-gramas\n",
        ")\n",
        "\n",
        "# 3.2 Confer√™ncia de seguran√ßa para garantir que est√° usando as stopwords corretas\n",
        "print(f\"Configura√ß√µes atribu√≠das:\")\n",
        "print(f\"- Idioma: {BERTOPIC_PARAMS['language']}\")\n",
        "print(f\"- Tamanho m√≠nimo de t√≥pico: {BERTOPIC_PARAMS['min_topic_size']}\")\n",
        "print(f\"- N-gram range: {BERTOPIC_PARAMS['n_gram_range']}\")\n",
        "print(f\"- Stopwords personalizadas: {CUSTOM_STOP_WORDS[:3]}... (total: {len(CUSTOM_STOP_WORDS)})\")\n",
        "print(f\" \")\n",
        "print(f\" Aguarde ...\")\n",
        "print(f\" \")\n",
        "\n",
        "# 3.3 Processamento dos documentos\n",
        "topics, probs = topic_model.fit_transform(docs)\n",
        "\n",
        "# 3.4 Armazenamento dos resultados\n",
        "df_result = df.copy()\n",
        "df_result[\"BERtopic\"] = topics\n",
        "\n",
        "print(f\"‚úÖ Modelo de classifica√ß√£o aplicado com sucesso!\")"
      ],
      "metadata": {
        "id": "aSRUiTzH98Rf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title 4Ô∏è‚É£ VISUALIZA√á√ïES DOS T√ìPICOS\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"üìã TABELA DE T√ìPICOS (ORDENADOS POR FREQU√äNCIA)\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# DataFrame com informa√ß√µes dos t√≥picos (Topic, Count, Name)\n",
        "topic_info = topic_model.get_topic_info()\n",
        "\n",
        "# Melhoria na exibi√ß√£o da tabela\n",
        "display(topic_info.style\n",
        "        .background_gradient(subset=['Count'], cmap='Blues')\n",
        "        .set_caption(\"T√≥picos identificados pelo BERTopic\"))\n",
        "\n",
        "# --------------------------------------------\n",
        "# üè∑Ô∏è MAPEAMENTO DE NOMES PARA T√ìPICOS\n",
        "# --------------------------------------------\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"üî§ PALAVRAS-CHAVE POR T√ìPICO\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Dicion√°rio de mapeamento (ID t√≥pico ‚Üí Nome)\n",
        "topic_map = {\n",
        "    row['Topic']: row['Name']\n",
        "    for _, row in topic_info.iterrows()\n",
        "}\n",
        "\n",
        "# Exibe palavras-chave de cada t√≥pico formatadas\n",
        "for topic_id in sorted(topic_info['Topic']):\n",
        "    palavras_chave = topic_model.get_topic(topic_id)\n",
        "\n",
        "    # Formata√ß√£o melhorada\n",
        "    palavras_formatadas = [\n",
        "        f\"{word} ({score:.2f})\"\n",
        "        for word, score in palavras_chave[:5]  # Top 5 palavras por t√≥pico\n",
        "    ]\n",
        "\n",
        "    print(f\"\\nüîπ T√≥pico {topic_id} ({topic_map.get(topic_id, 'Outlier')}):\")\n",
        "    print(\"   üìå Principais termos:\", \" | \".join(palavras_formatadas))\n",
        "    print(\"   üìä Documentos:\", topic_info[topic_info['Topic'] == topic_id]['Count'].values[0])\n",
        "\n",
        "# --------------------------------------------\n",
        "# üëÄ PR√âVIA DOS DADOS CLASSIFICADOS\n",
        "# --------------------------------------------\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"üìÑ AMOSTRA DOS RESULTADOS (5 primeiras e √∫ltimas linhas)\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Configura pandas para mostrar mais colunas\n",
        "pd.set_option('display.max_columns', None)\n",
        "\n",
        "# Exibe in√≠cio e fim do DataFrame\n",
        "print(\"\\n‚¨ÜÔ∏è PRIMEIRAS LINHAS:\")\n",
        "display(df_result.head().style.set_properties(**{\n",
        "    'background-color': '#f8f9fa',\n",
        "    'border': '1px solid #dee2e6'\n",
        "}))\n",
        "\n",
        "print(\"\\n‚¨áÔ∏è √öLTIMAS LINHAS:\")\n",
        "display(df_result.tail().style.set_properties(**{\n",
        "    'background-color': '#f8f9fa',\n",
        "    'border': '1px solid #dee2e6'\n",
        "}))\n",
        "\n",
        "\n",
        "# Recupera as estat√≠sticas originais do modelo\n",
        "raw_topic_info = topic_model.get_topic_info()\n",
        "\n",
        "# Calcula porcentagens\n",
        "total_raw_docs = raw_topic_info['Count'].sum()\n",
        "raw_topic_info['% do Total'] = (raw_topic_info['Count'] / total_raw_docs * 100).round(1)\n",
        "# EXIBI√á√ÉO INTERATIVA\n",
        "# --------------------------------------------------\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(f\"üìà DISTRIBUI√á√ÉO DOS {total_raw_docs} DOCUMENTOS\")\n",
        "print(\"=\"*60)\n",
        "display(raw_topic_info[['Topic', 'Name', 'Count', '% do Total']]\n",
        "        .rename(columns={\n",
        "            'Topic': 'ID T√≥pico',\n",
        "            'Name': 'Palavras-Chave (Auto)',\n",
        "            'Count': 'üìä Documentos'\n",
        "        })\n",
        "        .style\n",
        "        .format({'% do Total': '{:.1f}%'})\n",
        "        .bar(subset=['üìä Documentos'], color='#4b8bbe')\n",
        "        .set_caption(\"Distribui√ß√£o dos T√≥picos\"))\n"
      ],
      "metadata": {
        "id": "ECF-bkoI_ME4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# VERIFICA√á√ÉO DOS RESULTADOS\n",
        "\n",
        "‚úÖ SE OS RESULTADOS ACIMA ESTIVEREM SATISFAT√ìRIOS, PROSSIGA PARA AS PR√ìXIMAS C√âLULAS.\n",
        "\n",
        "‚ö†Ô∏è CASO CONTR√ÅRIO, VOLTE √Ä SE√á√ÉO 'CONFIGURA√á√ïES' E AJUSTE:\n",
        "1. CUSTOM_STOP_WORDS: Adicione termos irrelevantes que apareceram\n",
        "2. MIN_TOPIC_SIZE: Aumente para menos t√≥picos ou diminua para mais detalhado\n",
        "3. MAX_DOC_FREQ: Reduza para filtrar palavras muito frequentes\n",
        "\n",
        "üîÑ PROCEDIMENTO:\n",
        "1. Ajuste os par√¢metros\n",
        "2. Execute novamente desde o pr√©-processamento\n",
        "3. Verifique esta visualiza√ß√£o novamente\n",
        "\n",
        "üîé O QUE ANALISAR:\n",
        "1. T√≥picos com <5 docs podem ser fundidos ou descartados;\n",
        "2. Outliers (>20%) podem indicar necessidade de ajuste no modelo;\n",
        "3. Palavras-chave repetidas sugerem stopwords faltantes."
      ],
      "metadata": {
        "id": "2OSnEBqw_19n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üìä VISUALIZA√á√ïES INTERATIVAS DOS T√ìPICOS\n",
        "\n",
        "Esta se√ß√£o gera 3 tipos de visualiza√ß√µes para ajudar na interpreta√ß√£o dos t√≥picos:\n",
        "\n",
        "1Ô∏è‚É£ GR√ÅFICO DE BARRAS - Mostra as palavras mais relevantes de cada t√≥pico\n",
        "2Ô∏è‚É£ MAPA DE DIST√ÇNCIA - Ilustra como os t√≥picos se relacionam entre si\n",
        "3Ô∏è‚É£ MATRIZ DE SIMILARIDADE - Mostra o grau de similaridade entre t√≥picos\n",
        "\n",
        "üîç Como usar:\n",
        "- Passe o mouse sobre os elementos para ver detalhes\n",
        "- Clique e arraste para explorar os gr√°ficos\n",
        "- Use os menus interativos (quando dispon√≠veis)"
      ],
      "metadata": {
        "id": "S-JJMkfQBDgH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title 1Ô∏è‚É£ GR√ÅFICO DE BARRAS - PALAVRAS-CHAVE POR T√ìPICO\n",
        "# O que voc√™ est√° vendo:\n",
        "# - Cada barra representa um t√≥pico (exceto outliers -1)\n",
        "# - As palavras s√£o ordenadas por import√¢ncia (score)\n",
        "# - O comprimento da barra mostra a relev√¢ncia do termo\n",
        "#\n",
        "# O que observar:\n",
        "# - Se as palavras fazem sentido para o t√≥pico\n",
        "# - Se h√° termos irrelevantes que deveriam ser stopwords\n",
        "topic_model.visualize_barchart()"
      ],
      "metadata": {
        "id": "dqDpY16fAXTn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title 2Ô∏è‚É£ MAPA DE DIST√ÇNCIA - RELA√á√ÉO ENTRE T√ìPICOS\n",
        "# O que voc√™ est√° vendo:\n",
        "# - Cada bolha representa um t√≥pico\n",
        "# - T√≥picos pr√≥ximos s√£o semanticamente similares\n",
        "# - Tamanho da bolha = quantidade de documentos\n",
        "\n",
        "# O que observar:\n",
        "# - Agrupamentos naturais de t√≥picos\n",
        "# - T√≥picos isolados (potencialmente √∫nicos)\n",
        "# - Outliers distantes do n√∫cleo\n",
        "# - M√≠nimo de 4 t√≥picos para funcionar\n",
        "topic_model.visualize_topics()"
      ],
      "metadata": {
        "id": "9SApjv5CBTcH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title 3Ô∏è‚É£ MATRIZ DE SIMILARIDADE - AFINIDADE ENTRE T√ìPICOS\n",
        "# O que voc√™ est√° vendo:\n",
        "# - Tabela onde cada c√©lula mostra a similaridade (0-1)\n",
        "# - 1 = t√≥picos id√™nticos, 0 = completamente diferentes\n",
        "# - Diagonal principal sempre = 1 (autossimilaridade)\n",
        "\n",
        "# O que observar:\n",
        "# - T√≥picos com similaridade > 0.8 (potencial para fus√£o)\n",
        "# - T√≥picos √∫nicos (baixa similaridade com os demais)\n",
        "topic_model.visualize_heatmap()"
      ],
      "metadata": {
        "id": "XcfWxyv7DPS3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üè∑Ô∏è PERSONALIZA√á√ÉO DOS NOMES DOS T√ìPICOS (OPCIONAL)\n",
        "\n",
        "üìå ETAPA DE NOMEA√á√ÉO DOS T√ìPICOS\n",
        "\n",
        "Aqui voc√™ pode atribuir nomes descritivos aos t√≥picos identificados pelo modelo, substituindo os termos de palavras-chave por r√≥tulos significativos.\n",
        "\n",
        "‚úèÔ∏è COMO USAR:\n",
        "1. Analise as palavras-chave de cada t√≥pico (geradas anteriormente)\n",
        "2. Edite o dicion√°rio abaixo com nomes que representem cada grupo\n",
        "3. Execute a c√©lula para aplicar as mudan√ßas\n",
        "\n",
        "üñçÔ∏è EXEMPLO PR√ÅTICO:\n",
        "Se o t√≥pico 0 tem as palavras: \"aluno, ensino, personaliza√ß√£o\",\n",
        "um bom nome seria \"Personaliza√ß√£o do Ensino\"\n",
        "\n",
        "‚ö†Ô∏è IMPORTANTE:\n",
        "- Mantenha o t√≥pico -1 como \"Outliers\" (dados n√£o classificados)\n",
        "- Os n√∫meros devem corresponder aos IDs dos t√≥picos"
      ],
      "metadata": {
        "id": "r-3YcRzQENNP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dicion√°rio de mapeamento (ID -> Nome do t√≥pico)\n",
        "labels_map = {\n",
        "    -1: \"Outliers\",                       # Documentos n√£o classificados\n",
        "     0: \"Nome do T√≥pico 1\",\n",
        "     1: \"Nome do T√≥pico 2\",\n",
        "     2: \"Nome do T√≥pico 3\",\n",
        "     3: \"Nome do T√≥pico 4\",\n",
        "     4: \"Nome do T√≥pico 5\",\n",
        "}\n",
        "\n",
        "# --------------------------------------------\n",
        "# APLICA√á√ÉO DOS R√ìTULOS (n√£o precisa editar)\n",
        "# --------------------------------------------\n",
        "print(\"‚úÖ T√≥picos renomeados com sucesso!\")\n",
        "print(\"\\nüìã Rela√ß√£o de t√≥picos atualizada:\")\n",
        "for topic_id, topic_name in labels_map.items():\n",
        "    print(f\"T√≥pico {topic_id}: {topic_name}\")"
      ],
      "metadata": {
        "id": "271HOiaBERMH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üìå RESUMO DOS T√ìPICOS RENOMEADOS E VISUALIZA√á√ïES\n",
        "\n",
        "As c√©lulas abaixo geram resumos e visualiza√ß√µes dos t√≥picos com:\n",
        "- Nomes personalizados dos t√≥picos (definidos anteriormente)\n",
        "- Contagem de documentos associados a cada t√≥pico\n",
        "- Dados percentuais impl√≠citos (calculados sobre o total)\n",
        "\n",
        "‚ñ∏ O que voc√™ pode analisar:\n",
        "1. Distribui√ß√£o dos documentos entre t√≥picos\n",
        "2. Propor√ß√£o de outliers (t√≥pico -1)\n",
        "3. T√≥picos dominantes e minorit√°rios"
      ],
      "metadata": {
        "id": "zpzD_0-vFKW_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Obt√©m estat√≠sticas brutas do modelo\n",
        "topic_info = topic_model.get_topic_info()\n",
        "# Aplica os nomes personalizados dos t√≥picos\n",
        "topic_info['T√≥pico'] = topic_info['Topic'].map(labels_map)\n",
        "# Formata o quadro final de exibi√ß√£o\n",
        "quadro = topic_info.loc[:, ['T√≥pico', 'Count']].rename(\n",
        "    columns={'Count': 'Quantidade de Documentos'}\n",
        ")\n",
        "# Adiciona coluna de porcentagem\n",
        "total_docs = quadro['Quantidade de Documentos'].sum()\n",
        "quadro['% do Total'] = (quadro['Quantidade de Documentos'] / total_docs * 100).round(1)\n",
        "\n",
        "# EXIBI√á√ÉO FORMATADA (sa√≠da interativa)\n",
        "# --------------------------------------------------\n",
        "print(f\"\\nüîç Distribui√ß√£o dos {total_docs} documentos analisados\")\n",
        "print(f\" \")\n",
        "print(f\" \")\n",
        "display(quadro.style\n",
        "        .format({'% do Total': '{:.1f}%'})\n",
        "        .bar(subset=['Quantidade de Documentos'], color='#5fba7d')\n",
        "        .set_caption(\"Frequ√™ncia de Documentos por T√≥pico\"))\n"
      ],
      "metadata": {
        "id": "k5OvApueFGVf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Agora vamos fazer um gr√°fico com a distribui√ß√£o de itens por t√≥pico\n",
        "\n",
        "# Obter o DataFrame com frequ√™ncia de t√≥picos\n",
        "topic_info = topic_model.get_topic_info()\n",
        "# Aplicar os labels\n",
        "topic_info['Label'] = topic_info['Topic'].map(labels_map)\n",
        "# Montar a paleta de cores, reservando cinza para o t√≥pico -1\n",
        "palette = qualitative.Plotly  # ex: ['#636EFA', '#EF553B', '#00CC96', ...]\n",
        "topic_colors = {\n",
        "    -1:    'lightgrey',\n",
        "     0:    palette[0],\n",
        "     1:    palette[1],\n",
        "     2:    palette[2],\n",
        "     3:    palette[3],\n",
        "     4:    palette[4],\n",
        "}\n",
        "# Preparar os dados para o gr√°fico de pizza\n",
        "sizes  = topic_info['Count']\n",
        "labels = topic_info['Label']\n",
        "colors = [ topic_colors[t] for t in topic_info['Topic'] ]\n",
        "# Desenhar o gr√°fico\n",
        "fig, ax = plt.subplots(figsize=(8, 8))\n",
        "ax.pie(\n",
        "    sizes,\n",
        "    labels=labels,\n",
        "    colors=colors,\n",
        "    autopct='%1.1f%%',\n",
        "    startangle=90,\n",
        "    textprops={'color':'black'}\n",
        ")\n",
        "ax.axis('equal')  # garante c√≠rculo\n",
        "plt.title(\"Distribui√ß√£o de Itens por T√≥pico\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "bBf2ymEXIg8w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Agora vamos visualizar a matrix de similaridade com os nomes dos topicos que voce atribuiu:\n",
        "topic_model.set_topic_labels(labels_map)\n",
        "# Gerar o bar chart\n",
        "fig = topic_model.visualize_heatmap(custom_labels=True)\n",
        "# Atualizar o t√≠tulo\n",
        "fig.update_layout(\n",
        "    title_text=\"Matriz de Similaridade\",              # o texto que voc√™ quiser\n",
        "    # title_x=0.5,                                    # opcional: centraliza horizontalmente\n",
        "    # title_font_size=18                              # opcional: ajusta o tamanho da fonte\n",
        ")\n",
        "# Exibir\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "cZR4v0EnJXBA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Agora vamos visualizar o mapa de distancia entre topicos com os nomes dos topicos que voce sugeriu:\n",
        "from plotly.colors import qualitative\n",
        "topic_model.set_topic_labels(labels_map)\n",
        "# Gerar o gr√°fico normalmente\n",
        "fig = topic_model.visualize_topics(\n",
        "    custom_labels=True,\n",
        "    width=900,\n",
        "    height=700,\n",
        "    title=\"Mapa de Dist√¢ncia entre T√≥picos\"\n",
        ")\n",
        "# Preparar a paleta padr√£o\n",
        "palette = qualitative.Plotly\n",
        "# Mapear t√≥pico ‚Üí cor\n",
        "topic_colors = {topic: palette[i] for i, topic in enumerate(labels_map)}\n",
        "# Recolorir e adicione r√≥tulos internos com texto preto\n",
        "scatter = fig.data[0]\n",
        "# Extrair o √≠ndice do t√≥pico de cada bolha\n",
        "topics_in_fig = [int(row[0]) for row in scatter.customdata]\n",
        "# Aplicar a cor das bolhas\n",
        "scatter.marker.color = [topic_colors[t] for t in topics_in_fig]\n",
        "# Exibir o texto dentro das bolhas\n",
        "scatter.mode = 'markers+text'\n",
        "scatter.text = [labels_map[t] for t in topics_in_fig]\n",
        "scatter.textposition = 'middle center'\n",
        "# Ajustar fonte do texto\n",
        "scatter.textfont = dict(size=11, color='black')\n",
        "# Mostrar o gr√°fico\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "GjxThACzJnqg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üìä ENTENDENDO OS SCORES DE PALAVRAS-CHAVE\n",
        "\n",
        "O score (de 0 a 1) representa a import√¢ncia relativa de cada termo dentro de um t√≥pico, considerando:\n",
        "\n",
        "* FREQU√äNCIA: Qu√£o comum a palavra √© no t√≥pico espec√≠fico\n",
        "* DISTIN√á√ÉO: Qu√£o exclusiva ela √© desse t√≥pico (vs outros t√≥picos)\n",
        "\n",
        "‚ñ∞ Score 0.9 ‚Üí Palavra MUITO caracter√≠stica do t√≥pico\n",
        "\n",
        "‚ñ∞ Score 0.2 ‚Üí Palavra pouco representativa\n",
        "\n",
        "AN√ÅLISE PR√ÅTICA:\n",
        "* Barras mais longas = termos mais definidores do t√≥pico\n",
        "* Compare scores entre palavras do mesmo t√≥pico"
      ],
      "metadata": {
        "id": "9VzrXbhNK67g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Agora vamos plotar o score de palavras por t√≥pico.\n",
        "import math\n",
        "# === CONFIGURA√á√ÉO F√ÅCIL ===\n",
        "n_topics = len([k for k in labels_map.keys() if k != -1])  # Exclui outliers (-1)\n",
        "n_top_words  = 5   # quantas palavras principais exibir por t√≥pico\n",
        "n_cols       = 3   # quantas colunas por linha\n",
        "fig_width    = 4   # largura de cada subplot (em polegadas)\n",
        "fig_height   = 4   # altura de cada subplot (em polegadas)\n",
        "title        = \"Score de Palavras por T√≥pico\"\n",
        "\n",
        "# Montar a paleta padr√£o e mapear t√≥pico ‚Üí cor\n",
        "palette = qualitative.Plotly\n",
        "topic_colors = {topic: palette[i] for i, topic in enumerate(labels_map)}\n",
        "# Calcular layout\n",
        "n_rows = math.ceil(n_topics / n_cols)\n",
        "fig, axes = plt.subplots(\n",
        "    n_rows, n_cols,\n",
        "    figsize=(fig_width * n_cols, fig_height * n_rows),\n",
        "    sharex=False\n",
        ")\n",
        "fig.suptitle(title, fontsize=16)\n",
        "axes = axes.flatten()\n",
        "for idx in range(n_topics):\n",
        "    ax = axes[idx]\n",
        "    # Extrair as top n_top_words de cada t√≥pico (j√° em ordem decrescente)\n",
        "    topic_kw = topic_model.get_topic(idx)[:n_top_words]\n",
        "    words, scores = zip(*topic_kw)\n",
        "    # Plot horizontal e inverte eixo y para maior em cima\n",
        "    ax.barh(words, scores, color=topic_colors[idx])\n",
        "    ax.invert_yaxis()\n",
        "    ax.set_title(labels_map[idx], fontsize=12)\n",
        "    ax.set_xlabel(\"Score\")\n",
        "    ax.grid(axis=\"x\", linestyle=\"--\", alpha=0.5)\n",
        "\n",
        "# Desligar eixos extras se houver\n",
        "for j in range(n_topics, len(axes)):\n",
        "    axes[j].axis('off')\n",
        "\n",
        "plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "4lrVhb6aKGFv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5Ô∏è‚É£ EXPORTA√á√ÉO DOS RESULTADOS\n",
        "\n",
        "\n",
        "üíæ ETAPA FINAL: EXPORTAR RESULTADOS\n",
        "\n",
        "Aqui voc√™ pode salvar os resultados da an√°lise em formatos para:\n",
        "1. Publica√ß√£o web (HTML interativo)\n",
        "2. Compartilhamento (CSV)\n",
        "\n",
        "Escolha as op√ß√µes que deseja utilizar:"
      ],
      "metadata": {
        "id": "7CAGEmz2MGWg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title üåê OP√á√ÉO PARA WEB:\n",
        "# Gera um arquivo HTML com a matriz de similaridade entre t√≥picos, que pode ser embedado em sites ou compartilhado.\n",
        "\n",
        "# ‚ñ∏ Como usar:\n",
        "# 1. Execute esta c√©lula\n",
        "# 2. Encontre o arquivo 'topic_heatmap.html' no painel esquerdo\n",
        "# 3. Fa√ßa o download ou copie para seu servidor web\n",
        "\n",
        "heatmap_html = topic_model.visualize_heatmap()\n",
        "heatmap_html.write_html(\"topic_heatmap.html\")\n",
        "print(\"‚úÖ HTML interativo salvo como 'topic_heatmap.html'\")\n"
      ],
      "metadata": {
        "id": "ev02NK_JMNe4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title üìä EXPORTA√á√ÉO PARA CSV (AN√ÅLISE EM PLANILHAS)\n",
        "# --------------------------------------------------\n",
        "\n",
        "# Como usar:\n",
        "# 1. Execute esta c√©lula\n",
        "# 2. Clique no √≠cone üìÅ no menu esquerdo\n",
        "# 3. Localize 'resultado_topics.csv'\n",
        "# 4. Clique em ‚ãÆ ‚Üí Fazer download\n",
        "# Garante que a coluna Nome_Topico existe e est√° correta\n",
        "\n",
        "\n",
        "if 'Nome_Topico' not in df_result.columns:\n",
        "    df_result['Nome_Topico'] = df_result['BERtopic'].map(labels_map).fillna(\"Outliers\")\n",
        "else:\n",
        "    # Atualiza apenas os valores faltantes\n",
        "    df_result['Nome_Topico'] = df_result['Nome_Topico'].fillna(\n",
        "        df_result['BERtopic'].map(labels_map).fillna(\"Outliers\")\n",
        "    )\n",
        "\n",
        "# --------------------------------------------------\n",
        "# 2. EXPORTA√á√ÉO PARA CSV\n",
        "# --------------------------------------------------\n",
        "df_result.to_csv(\n",
        "    'resultado_topics.csv',\n",
        "    index=False,\n",
        "    encoding='utf-8-sig',  # Codifica√ß√£o que preserva acentos\n",
        "    columns=[col for col in df_result.columns if col != 'Unnamed: 0']  # Remove colunas indesejadas\n",
        ")\n",
        "print(\"\\n‚úÖ Dados classificados salvos como 'resultado_topics.csv'\")\n",
        "print(\"   Encoding: UTF-8 com BOM (compat√≠vel com Excel)\")"
      ],
      "metadata": {
        "id": "7dlFwXJaMsjw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "BERTopic: Neural topic modeling with a class-based TF-IDF procedure: https://doi.org/10.48550/arXiv.2203.05794"
      ],
      "metadata": {
        "id": "_y2aFd7WTPGw"
      }
    }
  ]
}